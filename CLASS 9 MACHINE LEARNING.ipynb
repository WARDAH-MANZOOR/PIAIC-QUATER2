{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning me humme rules nahi banane parte wo machine ke through khud banjate ,isme hum past data ke through learn karte hain \n",
    "\n",
    "# supervised learning me humme input bhibatana hota hai aur output bhi ,supervised learning \n",
    "# me predictions hoti hain \n",
    "\n",
    "# unsupervised me input hota hai srf matlab unsupervised wale kam se prediction wala kaam\n",
    "# nahi hota clustering waghaira ye cheezen unsupervised me ati hain\n",
    "\n",
    "# supervised me 2 parts hain:regression aur classification\n",
    "\n",
    "# regression me values par kaam karte matlab continuos values ati matlab jese agr mene aik mode\n",
    "# banana hai age predict karne ke liye tou wo age bataiga tou age humare paas regression me \n",
    "# jaaigi,matlab koi fixed answer nahi hoga har bande keliye alag output hoga \n",
    "\n",
    "# classification me agr humne model banan hai ke ye cat hai ya dog tou wo bataiya ke ye \n",
    "# cat hai tou ye classification hai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target names: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "print(\"Feature names:\", feature_names)\n",
    "print(\"Target names:\", target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of X:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "\n",
      " [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst 10 rows of X:\\n\", X[:10])\n",
    "print(\"\\n\",y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# versicolor ---- 0\n",
    "# setosa ---- 1\n",
    "# virginica---- 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X, y, test_size = 0.3, random_state = 1,shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "classifier_knn.fit(X_train, y_train) #Here training is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# Finding accuracy by comparing actual response values(y_test)with predicted response value(y_pred)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "# Providing sample data and the model will make prediction out of that data\n",
    "sample = [[5, 5, 3, 2], [2, 4, 3, 5]]\n",
    "preds = classifier_knn.predict(sample)\n",
    "print(preds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "pred_species = [iris.target_names[p] for p in preds]\n",
    "print(\"Predictions:\", pred_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shap: Explainable AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignment: Train a model using these algorithms:\n",
    "#Decision Tree\n",
    "#k-NN\n",
    "#Random forest\n",
    "#Support vector machines\n",
    "#NaiveBayes\n",
    "#Check accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_classifier_knn.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(classifier_knn, 'iris_classifier_knn.joblib') #save the model on computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('iris_classifier_knn.joblib') #reload the model from the file on computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[1,3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfitting matlab machine jo data humne dia hai usko itna rat le ke jab test karen tou usko wahi data yaad ho jo humne dia ho\n",
    "# underfit matlab train hi nahi hua ,usne kuch parha hi nahi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRECION AND RECALL\n",
    "\n",
    "# humne aik model banaya ke ubama president banega ya nahi \n",
    "# true positive---- ab humnebola ubama president banega aur wo banjata hai tou ye true positive hai\n",
    "# false positive ---humne kaha ban jaaiga aur nahi bana tou ye false positive hua\n",
    "# true negative ---- humne bola nahi banega aur nahi bana tou ye true negative\n",
    "# false negative-----humne kaha nahi bane ga banega aur bangaya false negative \n",
    "# precison = TP/TP+FP\n",
    "# recall = TP/TP+FN\n",
    "# PRECISON ---MATLAB MACHINE NE JITNI BHI POSITIVE PREDICTIONS KI USME SE SAHI KITNI HUI---jab usne postive kaha tou kitni bar sach kaha\n",
    "# RECALL ---JAB USKO actually positive bolna  CHAHIYE tha tab usne kitni bar positive kaha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1D\n",
    "[1,2,3,4]\n",
    "\n",
    "2D\n",
    "[\n",
    "    [1,2,3],\n",
    "    [1,2,3]\n",
    "]\n",
    "\n",
    "3D\n",
    "[\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [1,2,3]\n",
    "    ],\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [1,2,3]\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### statistics\n",
    "\n",
    "\n",
    "# mean = 1+3+2+4/4\n",
    "\n",
    "# median = 1,2,4,5,6=middle value---4\n",
    "\n",
    "# mode= 1,1,2,1,2,3 = most repeated value ----1\n",
    "\n",
    "# range = maximum value-minumum value\n",
    "\n",
    "# variance = Σ(Xi-Xmean)^2/n -----ye ye batatat hai ke humari values center mean se kitni hatti \n",
    "# hui hain,matlab kitna variance(change,difference) araha data me\n",
    "\n",
    "# standard deviation = square root of variance\n",
    "\n",
    "# correlation = (nΣXY - ΣXΣY) / sqrt[(nΣX^2 - (ΣX)^2)(nΣY^2 - (ΣY)^2)],correlation matlab ke 2 \n",
    "# variables hain tou wo apas me kitna corelated hain\n",
    "\n",
    "# agr 2 variables apas me bahut ziada correlated hain tou unki value aaiga +1 aur agr correlated \n",
    "# nahi hain tou -1 aaigi,ye hum ml me use karte hain matlb jese ml me bahut sare features hain\n",
    "# humare paas,aur hum chahrahe hon ke unme se kuch features ko kam karden,tou humare jo feautures\n",
    "# correlated honge jese agr 2features apas me correlated hain tou usme se koi bhi 1 ham hatta \n",
    "# sakte hain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "frame = pd.DataFrame({\n",
    "    'age': [12,13,14],\n",
    "    'salary': [34,37,39],\n",
    "    'life expectancy': [60,76,23]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>life expectancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993399</td>\n",
       "      <td>-0.680534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>0.993399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.591993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life expectancy</th>\n",
       "      <td>-0.680534</td>\n",
       "      <td>-0.591993</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      age    salary  life expectancy\n",
       "age              1.000000  0.993399        -0.680534\n",
       "salary           0.993399  1.000000        -0.591993\n",
       "life expectancy -0.680534 -0.591993         1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation\n",
    "frame.corr()\n",
    "# ye aese bataraha ke jese age aur salary hain pehli row me tou wo directly correlated hain \n",
    "# kuin ke age 1 hai aur salary 0.99 tou ye takreeban 1 hi hui tou ye directly correlated hue \n",
    "# ab agr ishi line me dekhen age aur life expectancy ko tou wo correlated nahi huin kuinke age \n",
    "# 1 hai aur life expectancy minus me jarahi tou ye correlated nahi hue ,ab hum chahen tou age ya salary me se kissi aik ko remove karsakte kuinke ye dono directly correlated hainn tou hum karsakte hain ye "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions---hum input dete hain tou output nikal kar araha hota hai,jese for example sinx ai function haijisme hum map kartehain x ko y par ,matlab x ki support dete y nikal kar ata hai ,function me 1 input par 1 hi output ata hai\n",
    "# relation me 1 input par multiple outputs bhi asakte\n",
    "# composition --misal ke tor par 2 functions hain aik f aur aik g,ab agr me is ko input doon x tou ye pehle g apply kare input par ---g(x),phr is anwer par  f apply kare---f(g(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR = Y_ACTUAL - Y_PREDICTED\n",
    "# MINIMA = WHEN DERIVATION IS EQUAL TO ZERO\n",
    "# LSS SHOULD BE IDEALLY ZERO/MINIMUM\n",
    "# LOSS = MSE(MEAN SQUARE ERROR)\n",
    "# GRADIENT DESCENT ALGORITHM:\n",
    "#     IF ERROR DERIVATIVE IS +VE --------- REDUCE WEIGHT\n",
    "#     IF ERROR DERIVATIVE IS -VE --------- INCREASE WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR REGRESSION BAHUT SAR POINTS ME BEST LINE FIND KARNE KI KOSHISH KARTA HAI\n",
    "# ----Y=MX+B,WHERE M IS SLOPE WHICH IS WEIGHT\n",
    "# B=BIAS MATLAB YE KE AESA DATA JESE MODFEL BANAYA HUMNE DRIVERLESS CARDS KA JO USA ME CHALATA HAI\n",
    "# AB ME PAKISTA ME USSE CHALONGI TOU WO NAHI CHALEGA KUINKE WAHAN DRIVING LEFT SIDE SE HOTI AUR\n",
    "# HUMARE YAHAN RIGHT PAR MATLAB KISSI KI SIDE LENA NATAIJ KO NAZARANDAZ KARKE SIDE DENA KISSI KI,\n",
    "# MATLAB YE KE DATA ME KOI AESI INFORMATION HONA JO HAR JAGA APPLY NA HO GENARALIZED NA HO,MATLAB\n",
    "# ACTUAL TRUTH SE HATTI HUI VALUE BIAS HOTA HAI\n",
    "# BIASNESS KO KHATAM KARNE LIYE YA TOU APNA DATA BARHAIN YA TOU BIAS KI TERM ADD KARDEN JESE KE\n",
    "# IS EQUATION ME ADD KI GAYE HAI Y=MX+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best capacity ka model select karna hota hai ml algorithm ussi waqt acha kaam karega jab \n",
    "# uski capacity appropriate ho,jo hum problem solve karna chahte hain uski complexity ke hisab\n",
    "# se right capacity wala model humme select karna hoga\n",
    "\n",
    "# nearest neighbour regression --- aik model haijisse hum train karwana chahrahe aur humare paas\n",
    "# x ki kuchvalues hain aur kuch nahi \n",
    "# x\n",
    "# 1\n",
    "# 4\n",
    "# 5\n",
    "# 10\n",
    "# par humare paas sari values majood nahijese 2,3 6,7,8,9 ki aur agr hum chahen ke hum 2 ki value\n",
    "# predict karen tou hum kia anaswer denge hum bolenge is ke qareeb qareeb jo points hain uska jo\n",
    "# anaswer hoga wahi 2 walae ka bhi answer hoga ya 1 aur 4 ka average nikal lo tou wo 2 ka answer \n",
    "# hoga ye cheez nearest neighbour regression kehlati hai ,matlab training ke anadr jo nearest\n",
    "# entry hai wo return karwado \n",
    "\n",
    "\n",
    "# neural network me neurons hote hain har neuron apni agli layer ke neuron se fully connected hota\n",
    "# hai ,input weight se multiply hote hain aur add hone ke baad matlab dot product nikalne ke baad\n",
    "# agay paas hoga ,pehli layer ko input layer kehte hain aur akhri layer ko output layer ,aur beech\n",
    "# wali layers hidden layers kehlati hain ,input layer aur output layer fixed hoti hain matlab aik\n",
    "#input layer aur aik utput layer par hidden layers hum jitni chahen rakh sakte hain,agr problem \n",
    "# complex hoga tou hum no. of hidden layers barha denge,agr problem simple hai tou no. of hidden \n",
    "# layers kam kardenge\n",
    "\n",
    "# hyper parameters ---- layes ki tadad har layer me kitne neurons lagane hain,model ki settings \n",
    "# hyper parameter hoti hain\n",
    "# no.of neurons in a layer ya no.of layers ye hyper parameter hain jo hum problem ke hisab se \n",
    "# change karte hain,aur joweight hai wo parameter hai,parameter training ke doran change horaha\n",
    "# hota jese yahan neural network me error ke hisab se weight adjust hota hai ,agr hyper parameter\n",
    "# change karenge tou dobara se training karwani paregi \n",
    "\n",
    "# hidden layers par activation functions bhi use kiye jate hum har layer par alag alag acctivation\n",
    "# function bhi lagasakte activation function data me non linearity handle karne ke liye use hota\n",
    "# hai matlab jo complexity problem me arahi usse hum activation function ke zariye handle karsakte\n",
    "# hain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias aur variance ke darmiyan tradeoff hota hai matlab agr hum kissi model me bias kam karna \n",
    "# chahte tou variance barh jata agr variance kam karna chahte tou bias barh jata inko alance karna\n",
    "# hota hai humme \n",
    "\n",
    "# logistic regression:\n",
    "#     agr humare paas linear regression hai uskajo output aaiga wo regression(continuous) hoga agr\n",
    "#     humne uspar classification karni hai tou hum kese karenge misal ke tor par jese humne male \n",
    "#     ya female batana hai tou hum kese batainge tou yahan humare paas sigmod ka function use hota\n",
    "#     hai jo ye raha  1/1+e^-x tou humare paaas jo output arha hoga usse hum is equation me put\n",
    "#     kardenge isse hoga kia ye humme aik number dega 0-1 ke darmiyan  jisko hum binary \n",
    "#     classification me use karsakte ,binary classification ke liye hum sigmoid use karte hain ,\n",
    "#     tou linear regression ke output ko 0,1 ki range me lane ke liye hum sigmoid use karenge \n",
    "#     is poori technique ka naam logistic regression hai \n",
    "\n",
    "# multi class classification me hum softmax use karenge \n",
    "\n",
    "# SUPPORT VECTOR MACHINE(SVM):\n",
    "        # BAZ OKAT DATA LOWER DIMENSIONAL ME ALAG NAHI OPATA HIGHER DIMENSION ME LEJAIN TOU ALAG HOJATA\n",
    "        # JESE KE 2 BANDE AGR AIK LINE ME KHARE HUE AB AGR WO AIK LINE KHARE HAIN TOU WO ONE DIMENSION ME \n",
    "        # SEPARATE NAHI HOSKATE MATLAB AIK LINE DRAW KARNE SE ALAG NAHIHOSAKTE AESE,\n",
    "        # *-------* NOT SEPATED BY ONE LINE *YE STERIC POINTS HAIN MATLAB 2 BANDE AUR BEECH ME JO LINE \n",
    "        # HAI WO INN KO SEPARATE KARNE KE LIYE LAGAI HAI\n",
    "\n",
    "        # AB AGR YAHI KAAM HUM 2 DIMENSION SE KAREN TOU SEPARTE HOJAINGE AESE \n",
    "        #     | \n",
    "        # *   |   * (YE DONO POINTS SEPARATE HOGAYE JAB HUMNE DOSRI DIMENSION SE LINE DRAW KI )\n",
    "        #     | \n",
    "\n",
    "        # DECICION TREE CLASSIFIER ---JESE HUMNE KISSI KE PERSONALITY BATANI HAI KE WO KSEA HAI TOU\n",
    "        # HUMNE USSE 20 QUESTIONS POOCHE AUR UN BASIS PAR BATADIA KE USKI PERSONALITY KESI HAI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR EXTRA DETAILS FOLLOW YOUTUBE CHANNEL \n",
    "# 'NOMAN ISLAM'\n",
    "\n",
    "\n",
    "# UNSUPERVISED LEARNING:\n",
    "#     K MEANS CLUSTERING: ----- DIVIDES DATA INTO GROUPS\n",
    "#         K MEANS CLUSTERING KE NAAM SE WO BOLTA HAI KE MENE DATA ME 4 CLSUTERS MALOOM KARNE HAI\n",
    "#         TOU WO KOI BHI 4 RANDOM POINTS SELECT KAREGA AUR USKO ASSUME KAREGA KE WO CLUSTER HAI MISAL\n",
    "#         KE TORPAR DATA HAI HUMARE PAAS USME KUCH POOINTS HAIN HUM NE POINTS RANDOM SELECT KIYE\n",
    "#         PHR HAR POINT JO  HUMNE RANDOM SELECT KIYE HAIN JO DOSRE POINTS USKE KAREEB HONGE WO US\n",
    "#         RANDOM POINT KE CLUSTER KE SHAMIL HOTE JAAINGE  AB JAB CLUSTERS BAN JAAINGE TOU YE DOBARA \n",
    "#         SE APNA CENTER CALCULATE KARENGE PHR WAHI PROCESS HOTA RAHEGA KE JO POINTS KAREB HONGE JIS\n",
    "#         CKUSTER KE WO USME ADD HOTE JAAINGEJAB SARE POINTS COMPLTE HOJAINGE AUR SARE CLUSTERS \n",
    "#         BANJAINGETOU YE KMEANS CLUSTER COMPLETE HOJAIGA \n",
    "#     PRINCIPLE COMPONENT ANALYSIS(PCA): ----REUCE DIMENSIONALITY \n",
    "#         JAB DATA KI DIMESION BAHUT ZIADA HO MATLAB FEATURES BAHUT ZIADA HO FEATURES ZIADA HINA\n",
    "#         KOI ACHI BAT NAHI HAI FEATURES KO KAM KARNE KE LIYE LOW DIMENSIONAL ME LANE KE PCA KI \n",
    "#         TECHNIQUE USE KARTE HAIN \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data using scikit-learn\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "input_data = np.array(\n",
    "   [\n",
    "      [2.1, -1.9, 5.5],\n",
    "      [-1.5, 2.4, 3.5],\n",
    "      [0.5, -7.9, 5.6],\n",
    "      [5.9, 2.3, -5.8]\n",
    "   ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Min max scaled data:\n",
      " [[0.48648649 0.58252427 0.99122807]\n",
      " [0.         1.         0.81578947]\n",
      " [0.27027027 0.         1.        ]\n",
      " [1.         0.99029126 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# scaling/normalization \n",
    "# AGR HUMARE DATA ME KUCH VALUES BARI HO KUCH CHOTI TOU HUMME UNHE SCALE KARNA PARTA HAI MATLAB\n",
    "# AIK STANDARD RANGE ME LANA HOTA HAI \n",
    "\n",
    "# DATA KO 0,1 KI RANGE ME LANA SCALING HAI \n",
    "data_scaler_minmax = preprocessing.MinMaxScaler(feature_range=(0,1)) # MINMAXSCALER DEKHEGA KE DATA ME HIGHEST VALUE KONSI HAI AUR LOWEST VALUE KONSI HAI ,USKO DIVIDE KARDEGA JO HIGHEST VALUE HOGI USSE 1 KE BARABAR KARDEGA JO LOWEST HOGI USSE 0 KE BARABAR KARDEGA \n",
    "data_scaled_minmax = data_scaler_minmax.fit_transform(input_data)\n",
    "print (\"\\nMin max scaled data:\\n\", data_scaled_minmax)\n",
    "# ye karne se humara data normalize hojata,agr hum isse normalizena karen tou ye hota hai ke derivative bahut tezi se jump karraha hota hai kabhi aik range me kabhi dosri me kabhi low range me jaraha kabhi infinite jaraha is cheez ko avoid karne ke liye hum normalization karte hain ab jese 2 columns hain aik age aik salary ab age aur salary hai tou dono ki ahmiat barabar hai par agr hum normalize nhi karenge tou salary ziada hoti tou wo uski ahmiat ziada samjhega is cheez ko khatam karne liye hum normalize karte apne data ko   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean se minus karke standard deviation se divide kia jata hai standard scaler me "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "X, y = load_iris(return_X_y = True)\n",
    "clf = SVC()\n",
    "clf.set_params(kernel = 'linear').fit(X, y) # YE JO KERNEL DIA HAI ISLIYE ME YE HYPERPARAMETER HAI YE NA BHI PAAS KAREMNGE TOU HUM KARSAKTE HAIN \n",
    "clf.predict(X[:5])\n",
    "clf.set_params(kernel = 'rbf', gamma = 'scale').fit(X, y)\n",
    "clf.predict(X[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT :USE ANY DATASET FROM kaggle.com apply any 5 ml classifiers,and upload on github \n",
    "# decision tree \n",
    "# knn\n",
    "# svm\n",
    "# naive bayes\n",
    "# logistic regression\n",
    "# calcualte accuracy,precison ,recall,F1-score,confusion matrix,ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Woman']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=[[165,19],[175,32],[136,35],[174,65],[141,28],[176,15],\n",
    "   [131,32],[166,6],[128,32],[179,10],[136,34],[186,2],[126,25],\n",
    "   [176,28],[112,38],[169,9],[171,36],[116,25],[196,25],\n",
    "   [196,38], [126,40], [197,20], [150,25], [140,32],[136,35]]\n",
    "Y=['Man','Woman','Woman','Man','Woman','Man','Woman','Man','Woman','Man','Woman',\n",
    "   'Man','Woman','Woman','Woman','Man','Woman','Woman','Man', 'Woman', 'Woman', 'Man', \n",
    "   'Man', 'Woman', 'Woman']\n",
    "data_feature_names = ['height','length of hair']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1)\n",
    "DTclf = tree.DecisionTreeClassifier()\n",
    "DTclf = clf.fit(X,Y)\n",
    "prediction = DTclf.predict([[135,29]])\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KMEAN\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.data.shape\n",
    "kmeans = KMeans(n_clusters = 10, random_state = 0) # make 10 clusters \n",
    "clusters = kmeans.fit_predict(digits.data)\n",
    "kmeans.cluster_centers_.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  1.66533454e-16,  3.07228916e-01,\n",
       "         7.16265060e+00,  1.19457831e+01,  1.93373494e+00,\n",
       "         1.50602410e-01,  5.42168675e-02,  1.73472348e-18,\n",
       "         1.20481928e-02,  3.28313253e+00,  1.37951807e+01,\n",
       "         8.46385542e+00,  1.53012048e+00,  9.75903614e-01,\n",
       "         2.77108434e-01,  8.67361738e-19,  6.44578313e-01,\n",
       "         1.07108434e+01,  1.15602410e+01,  4.33734940e+00,\n",
       "         5.25903614e+00,  3.87349398e+00,  3.25301205e-01,\n",
       "         6.02409639e-03,  4.75903614e+00,  1.47590361e+01,\n",
       "         5.86144578e+00,  6.87951807e+00,  1.07530120e+01,\n",
       "         6.21686747e+00,  1.80722892e-02,  0.00000000e+00,\n",
       "         8.92771084e+00,  1.48072289e+01,  9.35542169e+00,\n",
       "         1.28132530e+01,  1.43915663e+01,  5.48192771e+00,\n",
       "         0.00000000e+00,  9.63855422e-02,  6.50602410e+00,\n",
       "         1.16867470e+01,  1.23433735e+01,  1.48373494e+01,\n",
       "         1.07590361e+01,  1.56626506e+00,  1.38777878e-17,\n",
       "         6.02409639e-02,  1.11445783e+00,  3.00000000e+00,\n",
       "         7.77710843e+00,  1.40843373e+01,  4.13253012e+00,\n",
       "         1.80722892e-02, -5.55111512e-17,  2.16840434e-19,\n",
       "         2.40963855e-02,  3.73493976e-01,  7.96385542e+00,\n",
       "         1.23253012e+01,  1.77108434e+00,  0.00000000e+00,\n",
       "         2.22044605e-16],\n",
       "       [ 0.00000000e+00,  5.96590909e-01,  8.71590909e+00,\n",
       "         1.46306818e+01,  1.40454545e+01,  7.00568182e+00,\n",
       "         5.45454545e-01,  8.32667268e-17,  1.13636364e-02,\n",
       "         4.20454545e+00,  1.26022727e+01,  9.07386364e+00,\n",
       "         1.12386364e+01,  1.19602273e+01,  1.84659091e+00,\n",
       "         1.13636364e-02,  5.68181818e-03,  1.85795455e+00,\n",
       "         3.53977273e+00,  3.47159091e+00,  1.17897727e+01,\n",
       "         9.92613636e+00,  8.57954545e-01,  2.77555756e-17,\n",
       "         6.50521303e-19,  3.97727273e-02,  9.09090909e-01,\n",
       "         8.30681818e+00,  1.38295455e+01,  6.76704545e+00,\n",
       "         3.06818182e-01,  1.30104261e-18,  0.00000000e+00,\n",
       "         6.25000000e-02,  6.81818182e-01,  4.60227273e+00,\n",
       "         1.17613636e+01,  1.23125000e+01,  2.32954545e+00,\n",
       "         0.00000000e+00,  5.20417043e-18,  4.54545455e-01,\n",
       "         1.44318182e+00,  6.93181818e-01,  4.17613636e+00,\n",
       "         1.23693182e+01,  6.36363636e+00,  5.68181818e-03,\n",
       "         5.20417043e-18,  9.26136364e-01,  7.28409091e+00,\n",
       "         6.59090909e+00,  8.59659091e+00,  1.37215909e+01,\n",
       "         6.09090909e+00,  1.76136364e-01,  3.25260652e-19,\n",
       "         4.77272727e-01,  9.52840909e+00,  1.49829545e+01,\n",
       "         1.41420455e+01,  8.88068182e+00,  1.85227273e+00,\n",
       "         4.20454545e-01],\n",
       "       [ 0.00000000e+00,  1.10738255e+00,  1.00268456e+01,\n",
       "         1.34093960e+01,  1.41610738e+01,  1.25369128e+01,\n",
       "         4.37583893e+00,  4.02684564e-02,  6.71140940e-03,\n",
       "         4.55704698e+00,  1.49328859e+01,  1.25637584e+01,\n",
       "         8.70469799e+00,  7.03355705e+00,  2.47651007e+00,\n",
       "         3.35570470e-02,  1.34228188e-02,  6.07382550e+00,\n",
       "         1.45302013e+01,  5.95302013e+00,  1.97315436e+00,\n",
       "         1.02684564e+00,  2.01342282e-01,  6.93889390e-18,\n",
       "         6.71140940e-03,  5.30201342e+00,  1.43355705e+01,\n",
       "         1.23624161e+01,  7.85906040e+00,  2.26174497e+00,\n",
       "         1.47651007e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.94630872e+00,  8.15436242e+00,  1.00939597e+01,\n",
       "         1.02684564e+01,  5.51006711e+00,  6.37583893e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  3.02013423e-01,\n",
       "         1.39597315e+00,  4.87248322e+00,  9.87248322e+00,\n",
       "         7.02013423e+00,  7.78523490e-01,  1.38777878e-17,\n",
       "         4.33680869e-18,  8.05369128e-01,  5.06040268e+00,\n",
       "         9.47651007e+00,  1.21275168e+01,  5.27516779e+00,\n",
       "         4.42953020e-01, -8.32667268e-17,  0.00000000e+00,\n",
       "         1.05369128e+00,  1.08926174e+01,  1.45369128e+01,\n",
       "         7.83892617e+00,  1.08724832e+00,  2.01342282e-02,\n",
       "         1.66533454e-16],\n",
       "       [ 0.00000000e+00,  1.96000000e-01,  6.47600000e+00,\n",
       "         1.24800000e+01,  1.18560000e+01,  5.69600000e+00,\n",
       "         6.84000000e-01,  8.00000000e-03,  4.00000000e-03,\n",
       "         2.59200000e+00,  1.39640000e+01,  9.25200000e+00,\n",
       "         9.44000000e+00,  1.04560000e+01,  1.33600000e+00,\n",
       "         4.00000000e-03,  1.30104261e-18,  4.28000000e+00,\n",
       "         1.28560000e+01,  4.50800000e+00,  6.89200000e+00,\n",
       "         1.11400000e+01,  1.90400000e+00,  6.93889390e-17,\n",
       "        -6.50521303e-19,  2.31200000e+00,  1.03960000e+01,\n",
       "         1.17840000e+01,  1.31640000e+01,  1.20560000e+01,\n",
       "         2.45600000e+00, -1.30104261e-18,  0.00000000e+00,\n",
       "         3.00000000e-01,  3.17200000e+00,  6.17200000e+00,\n",
       "         6.84000000e+00,  1.12400000e+01,  4.23200000e+00,\n",
       "         0.00000000e+00, -5.20417043e-18,  2.28000000e-01,\n",
       "         2.37200000e+00,  1.98400000e+00,  1.76000000e+00,\n",
       "         1.10040000e+01,  6.37600000e+00,  1.60000000e-02,\n",
       "         1.73472348e-18,  7.60000000e-01,  8.10400000e+00,\n",
       "         5.66400000e+00,  4.76400000e+00,  1.22440000e+01,\n",
       "         5.97600000e+00,  1.12000000e-01, -3.25260652e-19,\n",
       "         1.68000000e-01,  6.38800000e+00,  1.34680000e+01,\n",
       "         1.44960000e+01,  9.94800000e+00,  2.30000000e+00,\n",
       "         1.12000000e-01],\n",
       "       [ 0.00000000e+00,  1.60194175e-01,  4.88834951e+00,\n",
       "         1.28689320e+01,  1.40631068e+01,  1.09805825e+01,\n",
       "         4.98543689e+00,  9.41747573e-01,  3.46944695e-18,\n",
       "         1.12135922e+00,  1.06553398e+01,  1.15145631e+01,\n",
       "         1.04320388e+01,  1.25825243e+01,  5.52427184e+00,\n",
       "         5.38834951e-01,  1.73472348e-18,  1.17961165e+00,\n",
       "         5.45145631e+00,  2.30097087e+00,  6.78640777e+00,\n",
       "         1.15339806e+01,  3.42233010e+00,  1.11650485e-01,\n",
       "         6.50521303e-19,  9.75728155e-01,  5.04368932e+00,\n",
       "         6.50000000e+00,  1.21553398e+01,  1.21067961e+01,\n",
       "         4.79611650e+00,  4.85436893e-03,  0.00000000e+00,\n",
       "         1.44660194e+00,  8.63592233e+00,  1.30679612e+01,\n",
       "         1.46796117e+01,  1.06893204e+01,  3.93203883e+00,\n",
       "         0.00000000e+00,  5.20417043e-18,  1.08252427e+00,\n",
       "         5.10194175e+00,  1.14611650e+01,  1.10388350e+01,\n",
       "         3.73300971e+00,  5.38834951e-01,  2.08166817e-17,\n",
       "         6.07153217e-18,  1.01941748e-01,  2.98058252e+00,\n",
       "         1.22572816e+01,  6.39805825e+00,  4.56310680e-01,\n",
       "         9.70873786e-03,  8.32667268e-17,  3.25260652e-19,\n",
       "         1.26213592e-01,  6.09223301e+00,  1.19660194e+01,\n",
       "         2.70388350e+00,  2.86407767e-01,  3.39805825e-02,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  2.23463687e-02,  4.22905028e+00,\n",
       "         1.31396648e+01,  1.12681564e+01,  2.93854749e+00,\n",
       "         3.35195531e-02,  8.32667268e-17,  1.73472348e-18,\n",
       "         8.82681564e-01,  1.26201117e+01,  1.33687151e+01,\n",
       "         1.14078212e+01,  1.13687151e+01,  9.60893855e-01,\n",
       "        -6.93889390e-17,  8.67361738e-19,  3.72625698e+00,\n",
       "         1.42122905e+01,  5.25139665e+00,  2.10614525e+00,\n",
       "         1.21173184e+01,  3.53072626e+00,  2.77555756e-17,\n",
       "         4.33680869e-19,  5.29608939e+00,  1.26424581e+01,\n",
       "         2.03351955e+00,  2.29050279e-01,  9.07821229e+00,\n",
       "         6.47486034e+00,  8.67361738e-19,  0.00000000e+00,\n",
       "         5.88268156e+00,  1.14916201e+01,  8.65921788e-01,\n",
       "         3.35195531e-02,  8.81005587e+00,  7.15083799e+00,\n",
       "         0.00000000e+00,  3.46944695e-18,  3.51396648e+00,\n",
       "         1.32849162e+01,  1.65921788e+00,  1.49162011e+00,\n",
       "         1.13519553e+01,  5.84357542e+00,  1.38777878e-17,\n",
       "         5.20417043e-18,  8.04469274e-01,  1.31117318e+01,\n",
       "         9.96089385e+00,  1.03519553e+01,  1.32960894e+01,\n",
       "         2.47486034e+00,  2.23463687e-02,  2.16840434e-19,\n",
       "         5.58659218e-03,  4.19553073e+00,  1.35865922e+01,\n",
       "         1.33407821e+01,  5.48044693e+00,  3.18435754e-01,\n",
       "         1.67597765e-02],\n",
       "       [ 0.00000000e+00,  1.11022302e-16,  3.33333333e-02,\n",
       "         1.68888889e+00,  1.10333333e+01,  1.25000000e+01,\n",
       "         4.14444444e+00,  2.44444444e-01,  1.73472348e-18,\n",
       "         5.55555556e-02,  1.87777778e+00,  8.85555556e+00,\n",
       "         1.39333333e+01,  1.23888889e+01,  5.10000000e+00,\n",
       "         3.22222222e-01,  8.67361738e-19,  1.62222222e+00,\n",
       "         8.74444444e+00,  1.27555556e+01,  1.23000000e+01,\n",
       "         1.29111111e+01,  3.82222222e+00,  1.44444444e-01,\n",
       "         2.16840434e-19,  3.62222222e+00,  1.21222222e+01,\n",
       "         1.19111111e+01,  1.31222222e+01,  1.35000000e+01,\n",
       "         2.50000000e+00,  4.33680869e-19,  0.00000000e+00,\n",
       "         1.92222222e+00,  6.85555556e+00,  7.23333333e+00,\n",
       "         1.16777778e+01,  1.25666667e+01,  1.84444444e+00,\n",
       "         0.00000000e+00,  1.73472348e-18,  8.11111111e-01,\n",
       "         1.97777778e+00,  3.76666667e+00,  1.16666667e+01,\n",
       "         1.18666667e+01,  1.21111111e+00,  3.46944695e-18,\n",
       "         1.73472348e-18,  6.66666667e-02,  3.22222222e-01,\n",
       "         2.91111111e+00,  1.24777778e+01,  1.17111111e+01,\n",
       "         1.67777778e+00, -8.32667268e-17,  1.08420217e-19,\n",
       "         1.11022302e-16,  8.88178420e-16,  1.76666667e+00,\n",
       "         1.12888889e+01,  1.07666667e+01,  1.74444444e+00,\n",
       "         5.55111512e-17],\n",
       "       [ 0.00000000e+00,  1.11607143e-01,  3.99107143e+00,\n",
       "         1.18839286e+01,  1.23214286e+01,  5.36160714e+00,\n",
       "         4.33035714e-01,  1.38777878e-16,  8.92857143e-03,\n",
       "         8.57142857e-01,  8.24553571e+00,  1.35446429e+01,\n",
       "         1.25625000e+01,  9.87500000e+00,  1.56696429e+00,\n",
       "        -8.32667268e-17,  1.30104261e-18,  1.21428571e+00,\n",
       "         8.37053571e+00,  1.18839286e+01,  1.23348214e+01,\n",
       "         9.46428571e+00,  1.02678571e+00,  5.55111512e-17,\n",
       "         6.50521303e-19,  9.41964286e-01,  7.26339286e+00,\n",
       "         1.40848214e+01,  1.41785714e+01,  4.95535714e+00,\n",
       "         2.00892857e-01,  1.30104261e-18,  0.00000000e+00,\n",
       "         7.67857143e-01,  8.00446429e+00,  1.47812500e+01,\n",
       "         1.29107143e+01,  2.18750000e+00,  1.78571429e-02,\n",
       "         0.00000000e+00,  5.20417043e-18,  1.22767857e+00,\n",
       "         1.04553571e+01,  1.20178571e+01,  1.21294643e+01,\n",
       "         4.02678571e+00,  2.00892857e-01,  2.08166817e-17,\n",
       "         1.33928571e-02,  8.75000000e-01,  9.57142857e+00,\n",
       "         1.15714286e+01,  1.20758929e+01,  5.57589286e+00,\n",
       "         6.16071429e-01,  4.46428571e-03,  4.46428571e-03,\n",
       "         1.11607143e-01,  4.20089286e+00,  1.20089286e+01,\n",
       "         1.25982143e+01,  4.85714286e+00,  8.08035714e-01,\n",
       "         8.92857143e-03],\n",
       "       [ 0.00000000e+00,  9.42857143e-01,  1.01885714e+01,\n",
       "         1.44400000e+01,  7.77142857e+00,  9.82857143e-01,\n",
       "        -1.11022302e-15,  5.55111512e-17,  2.28571429e-02,\n",
       "         5.24000000e+00,  1.37200000e+01,  1.26228571e+01,\n",
       "         1.16914286e+01,  3.23428571e+00,  1.71428571e-02,\n",
       "        -5.55111512e-17,  1.14285714e-02,  4.56000000e+00,\n",
       "         8.11428571e+00,  6.13714286e+00,  1.21600000e+01,\n",
       "         3.56000000e+00,  1.71428571e-02,  3.46944695e-17,\n",
       "         2.16840434e-19,  9.65714286e-01,  2.81714286e+00,\n",
       "         7.00571429e+00,  1.25371429e+01,  2.56000000e+00,\n",
       "         4.00000000e-02,  4.33680869e-19,  0.00000000e+00,\n",
       "         4.57142857e-02,  1.57142857e+00,  9.89714286e+00,\n",
       "         1.06971429e+01,  1.45142857e+00, -4.44089210e-16,\n",
       "         0.00000000e+00,  1.73472348e-18,  2.51428571e-01,\n",
       "         4.45714286e+00,  1.12457143e+01,  7.74285714e+00,\n",
       "         2.37142857e+00,  8.45714286e-01,  1.14285714e-02,\n",
       "         6.07153217e-18,  1.19428571e+00,  1.09942857e+01,\n",
       "         1.37314286e+01,  1.19257143e+01,  1.11600000e+01,\n",
       "         7.66857143e+00,  1.10285714e+00,  1.08420217e-19,\n",
       "         9.31428571e-01,  1.03885714e+01,  1.44685714e+01,\n",
       "         1.35028571e+01,  1.23542857e+01,  8.96571429e+00,\n",
       "         2.95428571e+00],\n",
       "       [ 0.00000000e+00,  1.66533454e-16,  1.15934066e+00,\n",
       "         1.12252747e+01,  9.53296703e+00,  1.41758242e+00,\n",
       "         5.49450549e-03,  8.32667268e-17,  8.67361738e-19,\n",
       "         6.04395604e-02,  7.18131868e+00,  1.45604396e+01,\n",
       "         6.19230769e+00,  8.29670330e-01,  2.74725275e-02,\n",
       "        -6.93889390e-17,  4.33680869e-19,  7.69230769e-01,\n",
       "         1.24560440e+01,  9.47252747e+00,  9.34065934e-01,\n",
       "         1.09890110e-01,  0.00000000e+00,  3.46944695e-17,\n",
       "         4.33680869e-19,  2.29670330e+00,  1.36208791e+01,\n",
       "         8.09340659e+00,  3.87362637e+00,  1.92857143e+00,\n",
       "         1.04395604e-01,  8.67361738e-19,  0.00000000e+00,\n",
       "         3.52747253e+00,  1.46758242e+01,  1.29175824e+01,\n",
       "         1.22527473e+01,  1.02857143e+01,  2.71978022e+00,\n",
       "         0.00000000e+00,  3.46944695e-18,  1.86813187e+00,\n",
       "         1.45164835e+01,  1.06538462e+01,  5.57692308e+00,\n",
       "         1.01923077e+01,  9.13186813e+00,  2.30769231e-01,\n",
       "         4.33680869e-18,  1.75824176e-01,  1.02857143e+01,\n",
       "         1.26263736e+01,  5.41758242e+00,  1.13241758e+01,\n",
       "         1.08956044e+01,  6.26373626e-01,  2.16840434e-19,\n",
       "         2.77555756e-16,  1.44505495e+00,  1.07362637e+01,\n",
       "         1.50989011e+01,  1.31318681e+01,  4.62087912e+00,\n",
       "         1.70329670e-01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_ # CENTER VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x170cc856bb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.data[0].reshape((8,8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMEANS\n",
    "X=[[165,19],[175,32],[136,35],[174,65],[141,28],[176,15],\n",
    "   [131,32],[166,6],[128,32],[179,10],[136,34],[186,2],[126,25],\n",
    "   [176,28],[112,38],[169,9],[171,36],[116,25],[196,25],\n",
    "   [196,38], [126,40], [197,20], [150,25], [140,32],[136,35]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters = 2, random_state = 0) # make 2 clusters \n",
    "clusters = kmeans.fit_predict(X)\n",
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[131.5       ,  31.75      ],\n",
       "       [178.92307692,  23.46153846]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
